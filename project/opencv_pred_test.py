import streamlit as st
import cv2
import time
import tempfile
import numpy as np
from ultralytics import YOLO

st.title("ğŸ”¥ YOLOv8 í™”ì¬/ì—°ê¸° íƒì§€ ì‹œìŠ¤í…œ")

# ğŸ¯ ëª¨ë¸ ì„ íƒ
model_option = st.selectbox(
    "ğŸ§  ëª¨ë¸ ì„ íƒ",
    [
        "YOLOv8n (ë¶ˆ ì „ìš©, ë¹ ë¦„)",
        "YOLOv8s (ë¶ˆ ì •í™•ë„â†‘)",
        "YOLOv8n-seg (ì—°ê¸°/ë¶ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜)",
    ],
)

model_path = {
    "YOLOv8n (ë¶ˆ ì „ìš©, ë¹ ë¦„)": "runs/firesmoke_detect_tuned2/weights/best.pt",
    "YOLOv8s (ë¶ˆ ì •í™•ë„â†‘)": "runs/firesmoke_yolov8s_tuned/weights/best.pt",
    "YOLOv8n-seg (ì—°ê¸°/ë¶ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜)": "runs/firesmoke_seg_train/weights/best.pt",
}

model = YOLO(model_path[model_option])

# ì…ë ¥ ë°©ì‹ ì„ íƒ
option = st.radio("ğŸ¥ ì…ë ¥ ì†ŒìŠ¤ ì„ íƒ", ["ì›¹ìº ", "ì˜ìƒ ì—…ë¡œë“œ"])
FRAME_WINDOW = st.image([])

# í†µê³„ ë³€ìˆ˜
frame_count = 0
inference_times = []
TEST_DURATION = 30  # í…ŒìŠ¤íŠ¸ ì‹œê°„ ì œí•œ


# ğŸ”§ ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ í•¨ìˆ˜
def is_valid_mask(mask, area_threshold=3000, center_tolerance=0.3):
    mask = mask.astype(np.uint8)
    h, w = mask.shape
    cx, cy = w // 2, h // 2
    center_roi = (
        int(cx - w * center_tolerance),
        int(cy - h * center_tolerance),
        int(cx + w * center_tolerance),
        int(cy + h * center_tolerance),
    )

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < area_threshold:
            continue
        x, y, rw, rh = cv2.boundingRect(cnt)
        if (center_roi[0] <= x <= center_roi[2]) and (
            center_roi[1] <= y <= center_roi[3]
        ):
            return True
    return False


# ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜
def process_video(cap, limit_time=30):
    global frame_count, inference_times
    frame_count = 0
    inference_times = []

    start_time = time.time()
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        t0 = time.time()
        results = model(frame, conf=0.7, iou=0.5, verbose=False, retina_masks=True)[0]
        t1 = time.time()

        valid_mask_count = 0
        if results.masks is not None:
            for m in results.masks.data:
                mask_np = m.cpu().numpy()
                if is_valid_mask(mask_np):
                    valid_mask_count += 1

        if valid_mask_count > 0:
            st.warning(f"ğŸš¨ ìœ„í—˜ ê°ì§€ë¨! ({valid_mask_count}ê°œ ì´ìƒ ìœ íš¨ ê°ì²´)")

        annotated = results.plot()
        FRAME_WINDOW.image(annotated, channels="BGR")

        inference_times.append(t1 - t0)
        frame_count += 1

        if time.time() - start_time >= limit_time:
            break

    cap.release()
    return time.time() - start_time


# ğŸ“¸ ì…ë ¥ ì†ŒìŠ¤ ì²˜ë¦¬
if option == "ì›¹ìº ":
    run = st.checkbox("â–¶ï¸ ì›¹ìº  ì‹¤í–‰")
    if run:
        st.success("âœ… ì›¹ìº  ì‹¤í–‰ë¨. 30ì´ˆ ë’¤ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
        cap = cv2.VideoCapture(0)
        elapsed_time = process_video(cap, TEST_DURATION)

elif option == "ì˜ìƒ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ğŸ¬ ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ", type=["mp4", "avi", "mov"])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        cap = cv2.VideoCapture(tfile.name)
        st.success("âœ… ì˜ìƒ ë¶„ì„ ì‹œì‘. ìµœëŒ€ 30ì´ˆ ë™ì•ˆ ë¶„ì„í•©ë‹ˆë‹¤.")
        elapsed_time = process_video(cap, TEST_DURATION)

# ğŸ“Š ê²°ê³¼ ì¶œë ¥
if frame_count > 0:
    avg_fps = frame_count / elapsed_time
    avg_infer_time = sum(inference_times) / len(inference_times)
    infer_fps = 1 / avg_infer_time if avg_infer_time > 0 else 0

    st.markdown("## ğŸ“Š ì¸¡ì • ê²°ê³¼")
    st.write(f"ğŸ” ì´ í”„ë ˆì„ ìˆ˜: {frame_count}")
    st.write(f"â±ï¸ ì´ ì¸¡ì • ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
    st.write(f"ğŸ“¸ í‰ê·  FPS (ì „ì²´): {avg_fps:.2f}")
    st.write(f"ğŸ§  í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_infer_time:.4f}ì´ˆ/frame")
    st.write(f"âš¡ ìˆœìˆ˜ ì¶”ë¡  ê¸°ì¤€ FPS: {infer_fps:.2f}")
