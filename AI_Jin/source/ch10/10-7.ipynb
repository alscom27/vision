{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Reshape,Flatten,Conv2D,Conv2DTranspose,LeakyReLU,Dropout\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "g4TxMhYQbajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train[np.isin(y_train.reshape([y_train.shape[0]]),[1])] # 부류 1(automobile) 추출\n",
        "x_train=(x_train.astype('float32')/255.0)*2.0-1.0 # [-1,1] 정규화\n",
        "\n",
        "zdim=100\t\t\t\t# 잠복 공간의 차원"
      ],
      "metadata": {
        "id": "LA2N9AjzbcIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator(in_shape):\t# 분별망 D\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(64,(3,3),padding='same',activation=LeakyReLU(alpha=0.2),input_shape=in_shape))\n",
        "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2)))\n",
        "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2)))\n",
        "    model.add(Conv2D(256,(3,3),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0002,beta_1=0.5),metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def make_generator(zdim): # 생성망 G\n",
        "    model=Sequential()\n",
        "    model.add(Dense(4*4*256,activation=LeakyReLU(alpha=0.2),input_dim=zdim))\n",
        "    model.add(Reshape((4,4,256)))\n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2))) # 8*8\n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2))) # 16*16\n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same',activation=LeakyReLU(alpha=0.2))) # 32*32\n",
        "    model.add(Conv2D(3,(3,3),padding='same',activation='tanh'))\n",
        "    return model\n",
        "\n",
        "def make_gan(G,D):\t\t\t# GAN 모델\n",
        "    D.trainable=False\n",
        "    model=Sequential()\n",
        "    model.add(G)\n",
        "    model.add(D)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0002,beta_1=0.5))\n",
        "    return model"
      ],
      "metadata": {
        "id": "DjzA-Ua9bc2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(dataset,n_samples):\t# 진짜 샘플 뽑음\n",
        "    ix=np.random.randint(0,dataset.shape[0],n_samples)\n",
        "    x=dataset[ix]\n",
        "    y=np.ones((n_samples,1))\n",
        "    return x,y\n",
        "\n",
        "def generate_latent_points(zdim,n_samples):\t# 잠복 공간 점 생성\n",
        "    return np.random.randn(n_samples,zdim)\n",
        "\n",
        "def generate_fake_samples(G,zdim,n_samples):\t# 가짜 샘플 생성\n",
        "    x_input=generate_latent_points(zdim,n_samples)\n",
        "    x=G.predict(x_input)\n",
        "    y=np.zeros((n_samples,1))\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "CjEawrB-bePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(G,D,GAN,dataset,zdim,n_epochs=200,batch_siz=128,verbose=0): # GAN 학습\n",
        "    n_batch=int(dataset.shape[0]/batch_siz)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for b in range(n_batch):\n",
        "            x_real,y_real=generate_real_samples(dataset,batch_siz//2)\n",
        "            d_loss1,_=D.train_on_batch(x_real,y_real)\t# 진짜 샘플로 D 학습\n",
        "            x_fake,y_fake=generate_fake_samples(G,zdim,batch_siz//2)\n",
        "            d_loss2,_=D.train_on_batch(x_fake,y_fake)\t# 가짜 샘플로 D 학습\n",
        "\n",
        "            x_gan=generate_latent_points(zdim,batch_siz)\n",
        "            y_gan=np.ones((batch_siz,1))\n",
        "            g_loss=GAN.train_on_batch(x_gan,y_gan)\t# G 학습\n",
        "        if verbose==1:\n",
        "            print('E%d: loss D(real)=%.3f, D(fake)%.3f GAN %.3f'%(epoch+1,d_loss1,d_loss2,g_loss))\n",
        "        if (epoch+1)%10==0:\n",
        "            x_fake,y_fake=generate_fake_samples(G,zdim,12)\n",
        "            plt.figure(figsize=(20,2))\n",
        "            plt.suptitle('epoch '+str(epoch+1))\n",
        "            for k in range(12):\n",
        "                plt.subplot(1,12,k+1)\n",
        "                plt.imshow((x_fake[k]+1)/2.0,cmap='gray'); plt.xticks([]); plt.yticks([])\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "JIH2JJcqbfTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTFHZMgFY-kU"
      },
      "outputs": [],
      "source": [
        "D=make_discriminator((32,32,3))\n",
        "G=make_generator(zdim)\n",
        "GAN=make_gan(G,D)\n",
        "train(G,D,GAN,x_train,zdim,verbose=1)"
      ]
    }
  ]
}